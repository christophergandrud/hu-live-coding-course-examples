{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Python version of UK Government speeches web scraping exercise  \n",
    "Christopher Gandrud (with ChatGPT 4)\n",
    "2023-05-13\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "all_href = []\n",
    "i = 0\n",
    "while True:\n",
    "    i += 1\n",
    "    url = f\"https://www.gov.uk/search/news-and-communications?level_one_taxon=5b7b9532-a775-4bd2-a3aa-6ce380184b6c&order=updated-newest&page={i}&people%5B%5D=boris-johnson\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    tmp_href = [link.get('href') for link in soup.select('#js-results div ul li a')]\n",
    "    if len(tmp_href) == 0:\n",
    "        break\n",
    "    all_href += tmp_href\n",
    "\n",
    "all_texts = pd.DataFrame()\n",
    "for href in all_href:\n",
    "    url_one = f\"https://www.gov.uk{href}\"\n",
    "    response = requests.get(url_one)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.select_one('#content div:nth-of-type(3) div:nth-of-type(1) div div:nth-of-type(1) div[data-module=\"govspeak\"]').text\n",
    "    tmp_df = pd.DataFrame({\"url\": [href], \"text\": [text]})\n",
    "    all_texts = pd.concat([all_texts, tmp_df], ignore_index=True)\n",
    "\n",
    "print(all_texts.describe())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the equivalent R code:\n",
    "\n",
    "```r\n",
    "xfun::pkg_attach2(\"roperators\", \"tidyverse\", \"rvest\") # use infix operator %+=%\n",
    "\n",
    "all_href <- character() # initialise all results object\n",
    "tmp_href <- 1 # initalise temp object\n",
    "i <- 0 # initalise counter\n",
    "while (length(tmp_href) > 0 ) {\n",
    "  i %+=% 1\n",
    "  url <- paste0(\"https://www.gov.uk/search/news-and-communications?\",\n",
    "                \"level_one_taxon=5b7b9532-a775-4bd2-a3aa-6ce380184b6c&\",\n",
    "                \"order=updated-newest&page=\", \n",
    "                as.character(i), \n",
    "                \"&people%5B%5D=boris-johnson\")\n",
    "  tmp_href <- read_html(url) %>%\n",
    "              html_elements(xpath = '//*[@id=\"js-results\"]/div/ul/li[*]/a') %>%\n",
    "                         html_attr('href')\n",
    "  all_href <- c(all_href, tmp_href)\n",
    "}\n",
    "\n",
    "all_texts <- data.frame()\n",
    "for (i in seq(all_href)) {\n",
    "  url_one <- paste0(\"https://www.gov.uk\", all_href[i])\n",
    "  # message(url_one)\n",
    "  full_html <- read_html(url_one)\n",
    "  text <-  full_html %>% \n",
    "    html_nodes(xpath = \n",
    "      paste0('//*[@id=\"content\"]/div[3]/div[1]/div',\n",
    "             '/div[1]/div[contains(@data-module, \"govspeak\")]')) %>% \n",
    "    html_text()\n",
    "  tmp_df <- data.frame(url = all_href[i], text = text)\n",
    "  all_texts <- bind_rows(all_texts, tmp_df)\n",
    "}\n",
    "announce_corpus <- corpus(all_texts)\n",
    "summary(announce_corpus)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
